{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kai/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/kai/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "# import kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /Users/kai/Library/Python/3.9/lib/python/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/kai/Library/Python/3.9/lib/python/site-packages (from scipy) (2.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "# import os\n",
    "# import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "# import kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'edges_df.pk1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     edges_df_sorted \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m path2\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataframes/edges_df.pk1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges_df.pk1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m     edges_df \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     11\u001b[0m path3\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataframes/df_aggregated.pk1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'edges_df.pk1'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "path1 = \"../dataframes/edges_df_sorted.pk1\"\n",
    "with open(path1, \"rb\") as f:\n",
    "    edges_df_sorted = pickle.load(f)\n",
    "\n",
    "path2= \"../dataframes/edges_df.pk1\"\n",
    "with open(path2, \"rb\") as f:\n",
    "    edges_df = pickle.load(f)\n",
    "\n",
    "path3= \"../dataframes/df_aggregated.pk1\"\n",
    "with open(path3, \"rb\") as f:\n",
    "    df_aggregated = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore, didn't know 'pain after an operation' would be a disease\n",
    "disease_of_interest = \"pain after an operation\"\n",
    "\n",
    "filtered_edges = edges_df[(edges_df[\"Disease1\"] == disease_of_interest) | (edges_df[\"Disease2\"] == disease_of_interest)]\n",
    "\n",
    "print(filtered_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row[\"Disease1\"], row[\"Disease2\"], weight=row[\"Weight\"])\n",
    "\n",
    "print(\"Nodes:\", G.number_of_nodes())\n",
    "\n",
    "print(\"Edges:\", G.number_of_edges())\n",
    "print(\"Network Density\" , nx.density(G))\n",
    "#Network density is 0.22, which is fairly low. 1.0 would be a fully connected graph\n",
    "#There are some distinct cluters, some diseases share symptoms, and others are only connected to a few\n",
    "#Some diseases have a specific symptom profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute degree distribution\n",
    "degrees = [G.degree(n) for n in G.nodes()]\n",
    "average_degree = np.mean(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot degree distribution\n",
    "plt.hist(degrees, bins=20)\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Degree Distribution of Diseases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram (linear scale)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(degrees, bins=20, color='b', alpha=0.6, edgecolor='black')\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Degree Distribution of Diseases\")\n",
    "plt.figtext(0.15, 0.85, f'Avg Degree: {average_degree:.2f}', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Log Plot (to check power-law behavior)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(degrees, bins=np.logspace(np.log10(min(degrees)), np.log10(max(degrees)), 20), color='g', alpha=0.6, edgecolor='black')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Degree (log)\")\n",
    "plt.ylabel(\"Frequency (log)\")\n",
    "plt.title(\"Log-Log Degree Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a power-law distribution\n",
    "fit = powerlaw.Fit(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with fitted power-law\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "fit.plot_pdf(color='b', linewidth=2, label=\"Empirical Data\")\n",
    "fit.power_law.plot_pdf(color='r', linestyle=\"--\", label=\"Power-Law Fit\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.title(\"Power-Law Fit to Degree Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print estimated power-law exponent\n",
    "print(f\"Estimated power-law exponent: {fit.power_law.alpha:.2f}\")\n",
    "print(f\"Power-law fit xmin: {fit.power_law.xmin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted from networkX cpsc 572 lecture winter 2025\n",
    "N = len(G)\n",
    "L = G.size()\n",
    "degrees = [G.degree(node) for node in G]\n",
    "kmin = min(degrees)\n",
    "kmax = max(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes: \", N)\n",
    "print(\"Number of edges: \", L)\n",
    "print()\n",
    "print(\"Average degree: \", 2*L/N)\n",
    "print(\"Average degree (alternate calculation)\", np.mean(degrees))\n",
    "print()\n",
    "print(\"Minimum degree: \", kmin)\n",
    "print(\"Maximum degree: \", kmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Degree Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Log Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10 logarithmically spaced bins between kmin and kmax\n",
    "# buckets un from minimum degree to maximum degree\n",
    "bin_edges = np.logspace(np.log10(kmin), np.log10(kmax), num=10)\n",
    "\n",
    "# histogram the data into these bins\n",
    "density, _ = np.histogram(degrees, bins=bin_edges, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "# \"x\" should be midpoint (IN LOG SPACE) of each bin\n",
    "log_be = np.log10(bin_edges)\n",
    "x = 10**((log_be[1:] + log_be[:-1])/2)\n",
    "\n",
    "plt.loglog(x, density, marker='o', linestyle='none')\n",
    "plt.xlabel(r\"degree $k$\", fontsize=16)\n",
    "plt.ylabel(r\"$P(k)$\", fontsize=16)\n",
    "\n",
    "# Adding a line for better visual \n",
    "plt.loglog(x, density, linestyle='-', color='gray', linewidth=0.5, alpha=0.6, label=\"Trend Line\")\n",
    "\n",
    "# remove right and top boundaries because they're ugly\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Adjusting x-axis numbers for readability\n",
    "custom_ticks = [50, 100, 150, 200]  \n",
    "ax.set_xticks(custom_ticks)\n",
    "ax.set_xticklabels(custom_ticks)  # Ensure they display as integers\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.tick_params(axis='x', which='major', labelsize=12, rotation=30)  \n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-Linear Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE BELOW TAKEN FROM CPSC 572 LECTURE ON NETWORKX (WINTER 2025)\n",
    "# Get 20 logarithmically spaced bins between kmin and kmax\n",
    "bin_edges = np.linspace(kmin, kmax, num=10)  # number of bins (num=10) can be changed\n",
    "\n",
    "# histogram the data into these bins\n",
    "density, _ = np.histogram(degrees, bins=bin_edges, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "# \"x\" should be midpoint (IN LOG SPACE) of each bin\n",
    "log_be = np.log10(bin_edges)\n",
    "x = 10**((log_be[1:] + log_be[:-1])/2)\n",
    "\n",
    "plt.plot(x, density, marker='o', linestyle='none')\n",
    "plt.xlabel(r\"degree $k$\", fontsize=16)\n",
    "plt.ylabel(r\"$P(k)$\", fontsize=16)\n",
    "\n",
    "# Adding a line for better visual \n",
    "plt.plot(x, density, linestyle='-', color='gray', linewidth=0.5, alpha=0.6, label=\"Trend Line\")\n",
    "\n",
    "# remove right and top boundaries\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using force-based or \"spring\" layout algorithm for 50% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample about 25% of the nodes\n",
    "total_nodes = len(G.nodes())\n",
    "sampled_nodes = int(total_nodes * 0.25) # Extract 25% of all nodes\n",
    "final_sampled_nodes = random.sample(G.nodes(), sampled_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subgraph of nodes\n",
    "subgraph = G.subgraph(final_sampled_nodes)\n",
    "\n",
    "# Visualize the subgraph using Force-Based Layout\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Force-Based Layout Using 25% Subsample\")\n",
    "pos_force = nx.spring_layout(subgraph, seed=42)  # force-directed layout\n",
    "nx.draw(subgraph, pos=pos_force, with_labels=False, node_size=50, edge_color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using force-based or \"spring\" layout algorithm for 10% of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample about 10% of the nodes\n",
    "total_nodes = len(G.nodes())\n",
    "sampled_nodes = int(total_nodes * 0.10) # Extract 10% of all nodes\n",
    "final_sampled_nodes = random.sample(G.nodes(), sampled_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subgraph of nodes\n",
    "subgraph = G.subgraph(final_sampled_nodes)\n",
    "\n",
    "# Visualize the subgraph using Force-Based Layout\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Force-Based Layout Using 10% Subsample\")\n",
    "pos_force = nx.spring_layout(subgraph, seed=42)  # force-directed layout\n",
    "nx.draw(subgraph, pos=pos_force, with_labels=False, node_size=50, edge_color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the fcircular layout algorithm using 10% of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Circular Layout Using 10% Subsample\")\n",
    "pos_circular = nx.circular_layout(subgraph)  # circular layout\n",
    "nx.draw(subgraph, pos=pos_circular, with_labels=False, node_size=50, edge_color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-louvain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "\n",
    "# Detect communities using Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "\n",
    "# Color nodes based on community detection results\n",
    "node_color = [partition[node] for node in subgraph.nodes()]\n",
    "\n",
    "# Plot with community-based colors\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(subgraph, pos, node_color=node_color, cmap=plt.cm.RdYlBu, node_size=300)\n",
    "plt.title(\"Community-Louvain Visual Using 10% Subsample\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 diseases by Degree Centrality:\", sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "#these diseases have the highest number of direct symptom based connections to other diseases\n",
    "\n",
    "#Drug reaction:\n",
    "    #high connectivity suggests drug-induced conditions are frequently misdiagnosed as other illnesses.\n",
    "    \n",
    "#Pain after an operation:\n",
    "    #Post operation pain is common across many surgical procedures and may be mistaken for underlying infections or some other issues\n",
    "    \n",
    "#Shingles:\n",
    "    #High centrality suggests it may often be confused with other viral infections or autoimmune conditions.\n",
    "    \n",
    "#Acute Stress Reaction:\n",
    "    #indicates stress-related symptoms might contribute to misdiagnosis of physical diseases.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 diseases by Betweenness Centrality:\", sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "#Shingles:\n",
    "    #Shingles has symptoms (nerve pain, rashes, fever) that overlap with both viral infections and autoimmune conditions.\n",
    "    #This suggests shingles acts as a key diagnostic confusion point, potentially being mistaken for other neurological, dermatological, or viral illnesses.\n",
    "    \n",
    "#Parasitic disease:\n",
    "    #Many parasitic diseases have vague symptoms (abdominal pain, diarrhea, fatigue), which means they might connect conditions like food poisoning, viral infections, and malabsorption disorders.\n",
    "    \n",
    "#Drug Reaction:\n",
    "    #High betweenness suggests that drug reactions bridge multiple medical conditions, leading to frequent confusion with infections, allergies, or autoimmune issues.\n",
    "    \n",
    "#These diseases connect different clusters, making them major misdiagnosis risks.\n",
    "#Doctors should carefully differentiate these from diseases in both of their clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 diseases by Closeness Centrality:\", sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "#These diseases are highly reachable in the network, meaning they are common misdiagnosis or differential diagnosis candidates.\n",
    "#Doctors should always consider these diseases in diagnostic decisions since they connect to many symptomatically similar conditions.\n",
    "#These diseases may be important in machine learning models for automated diagnosis, as they likely appear as early-stage possibilities in differential diagnoses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 diseases by Eigenvector Centrality:\", sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "\n",
    "#Since it is so interconnected, doctors should always consider checking for underlying causes of hypokalemia, as it may be a secondary symptom of another major condition.\n",
    "\n",
    "#understanding postoperative symptom patterns could help reduce unnecessary tests and avoid confusion with unrelated conditions.\n",
    "\n",
    "#These diseases act as key “hubs” in the network, influencing diagnosis patterns across multiple categories.\n",
    "#Diseases with high eigenvector centrality may serve as key “signals” in differential diagnosis algorithms.\n",
    "#Misdiagnosis risks are high when these diseases are confused with others that have similar symptoms but different underlying causes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
